# -*- coding: utf-8 -*-
"""
LLMå®¢æˆ·ç«¯å•å…ƒæµ‹è¯•

æµ‹è¯•LLMå®¢æˆ·ç«¯çš„æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬APIè°ƒç”¨ã€é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶ç­‰ã€‚

æµ‹è¯•è¦†ç›–ï¼š
1. LLMå®¢æˆ·ç«¯åˆå§‹åŒ–
2. èŠå¤©APIè°ƒç”¨
3. æ¶ˆæ¯æ ¼å¼å¤„ç†
4. é”™è¯¯å¤„ç†å’Œé‡è¯•
5. è¶…æ—¶å¤„ç†
6. å“åº”è§£æ
7. å¯¹è¯å†å²ç®¡ç†

è®¾è®¡åŸåˆ™ï¼š
- å®Œæ•´çš„åŠŸèƒ½è¦†ç›–
- æ¨¡æ‹Ÿå¤–éƒ¨APIè°ƒç”¨
- ç½‘ç»œé”™è¯¯æ¨¡æ‹Ÿ
- è¾¹ç•Œæ¡ä»¶æµ‹è¯•
"""
import pytest
import json
import requests
from unittest.mock import Mock, patch, MagicMock
from typing import Dict, List, Any

# å¯¼å…¥è¢«æµ‹è¯•çš„æ¨¡å—
try:
    from src.models.llm_client import LLMClient
except ImportError as e:
    print(f"å¯¼å…¥è­¦å‘Š: {e}")

    # åˆ›å»ºæ¨¡æ‹Ÿç±»ç”¨äºæµ‹è¯•
    class LLMClient:
        def __init__(self, api_key="test_key", api_url="https://test.api.com", model="test-model"):
            self.api_key = api_key
            self.api_url = api_url
            self.model = model
            self.system_prompt = "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"

        def chat(self, user_message: str, context_info: str = "", conversation_history: List[Dict] = None) -> str:
            return "æµ‹è¯•AIå›å¤"


class TestLLMClient:
    """æµ‹è¯•LLMå®¢æˆ·ç«¯ç±»"""

    @pytest.fixture
    def llm_client(self):
        """åˆ›å»ºLLMå®¢æˆ·ç«¯å®ä¾‹"""
        # æ¨¡æ‹Ÿç¯å¢ƒå˜é‡
        with patch.dict('os.environ', {
            'LLM_API_KEY': 'test_api_key',
            'LLM_API_URL': 'https://test.api.com/v1/chat/completions',
            'LLM_MODEL': 'test-model'
        }):
            # æ¨¡æ‹Ÿprintå‡½æ•°é¿å…è¾“å‡º
            with patch('builtins.print'):
                return LLMClient()

    @pytest.mark.chat
    def test_llm_client_initialization(self, llm_client):
        """æµ‹è¯•LLMå®¢æˆ·ç«¯åˆå§‹åŒ–"""
        assert llm_client.api_key == "test_api_key"
        assert llm_client.api_url == "https://test.api.com/v1/chat/completions"
        assert llm_client.model == "test-model"
        assert hasattr(llm_client, 'system_prompt')
        assert "æœè”¬å®¢æœAIåŠ©æ‰‹" in llm_client.system_prompt

    @pytest.mark.chat
    def test_chat_success(self, llm_client):
        """æµ‹è¯•æˆåŠŸçš„èŠå¤©è°ƒç”¨"""
        user_message = "ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆæ°´æœæ¨èï¼Ÿ"
        context_info = "å½“å‰æœ‰è‹¹æœã€é¦™è•‰ã€æ©™å­ç­‰æ°´æœ"

        # æ¨¡æ‹ŸæˆåŠŸçš„APIå“åº”
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'choices': [
                {
                    'message': {
                        'content': 'æ¨èæ‚¨è¯•è¯•æˆ‘ä»¬çš„çº¢å¯Œå£«è‹¹æœï¼Œå£æ„Ÿè„†ç”œï¼Œè¥å…»ä¸°å¯Œã€‚'
                    }
                }
            ]
        }

        with patch('requests.post', return_value=mock_response) as mock_post:
            result = llm_client.chat(user_message, context_info)

            assert result == 'æ¨èæ‚¨è¯•è¯•æˆ‘ä»¬çš„çº¢å¯Œå£«è‹¹æœï¼Œå£æ„Ÿè„†ç”œï¼Œè¥å…»ä¸°å¯Œã€‚'

            # éªŒè¯APIè°ƒç”¨å‚æ•°
            mock_post.assert_called_once()
            call_args = mock_post.call_args

            # éªŒè¯URL
            assert call_args[0][0] == llm_client.api_url

            # éªŒè¯headers
            headers = call_args[1]['headers']
            assert 'Authorization' in headers
            assert headers['Authorization'] == f"Bearer {llm_client.api_key}"
            assert headers['Content-Type'] == 'application/json'

            # éªŒè¯è¯·æ±‚æ•°æ®
            request_data = call_args[1]['json']
            assert request_data['model'] == llm_client.model
            assert 'messages' in request_data
            assert len(request_data['messages']) >= 2  # è‡³å°‘åŒ…å«systemå’Œuseræ¶ˆæ¯

    @pytest.mark.chat
    def test_chat_with_conversation_history(self, llm_client):
        """æµ‹è¯•å¸¦å¯¹è¯å†å²çš„èŠå¤©"""
        user_message = "é‚£é¦™è•‰æ€ä¹ˆæ ·ï¼Ÿ"
        conversation_history = [
            {'role': 'user', 'content': 'æœ‰ä»€ä¹ˆæ°´æœæ¨èï¼Ÿ'},
            {'role': 'assistant', 'content': 'æ¨èè‹¹æœ'}
        ]

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'choices': [
                {'message': {'content': 'é¦™è•‰ä¹Ÿå¾ˆä¸é”™ï¼Œå¯Œå«é’¾å…ƒç´ ã€‚'}}
            ]
        }

        with patch('requests.post', return_value=mock_response) as mock_post:
            result = llm_client.chat(user_message, "", conversation_history)

            assert result == 'é¦™è•‰ä¹Ÿå¾ˆä¸é”™ï¼Œå¯Œå«é’¾å…ƒç´ ã€‚'

            # éªŒè¯å¯¹è¯å†å²è¢«åŒ…å«åœ¨è¯·æ±‚ä¸­
            request_data = mock_post.call_args[1]['json']
            messages = request_data['messages']

            # åº”è¯¥åŒ…å«systemã€å†å²æ¶ˆæ¯å’Œå½“å‰ç”¨æˆ·æ¶ˆæ¯
            assert len(messages) >= 4  # system + 2æ¡å†å² + 1æ¡å½“å‰

            # éªŒè¯å†å²æ¶ˆæ¯è¢«æ­£ç¡®åŒ…å«
            user_messages = [msg for msg in messages if msg['role'] == 'user']
            assert len(user_messages) >= 2

    @pytest.mark.chat
    def test_chat_with_context_info(self, llm_client):
        """æµ‹è¯•å¸¦ä¸Šä¸‹æ–‡ä¿¡æ¯çš„èŠå¤©"""
        user_message = "è‹¹æœçš„ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ"
        context_info = "çº¢å¯Œå£«è‹¹æœï¼š8.5å…ƒ/æ–¤ï¼Œåº“å­˜ï¼š100æ–¤"

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'choices': [
                {'message': {'content': 'çº¢å¯Œå£«è‹¹æœçš„ä»·æ ¼æ˜¯8.5å…ƒ/æ–¤ã€‚'}}
            ]
        }

        with patch('requests.post', return_value=mock_response) as mock_post:
            result = llm_client.chat(user_message, context_info)

            # éªŒè¯ä¸Šä¸‹æ–‡ä¿¡æ¯è¢«åŒ…å«åœ¨ç”¨æˆ·æ¶ˆæ¯ä¸­
            request_data = mock_post.call_args[1]['json']
            messages = request_data['messages']

            user_message_content = None
            for msg in messages:
                if msg['role'] == 'user':
                    user_message_content = msg['content']
                    break

            assert user_message_content is not None
            assert context_info in user_message_content or "ç›¸å…³ä¿¡æ¯" in user_message_content

    @pytest.mark.chat
    def test_chat_api_error_4xx(self, llm_client):
        """æµ‹è¯•API 4xxé”™è¯¯"""
        user_message = "æµ‹è¯•æ¶ˆæ¯"

        mock_response = Mock()
        mock_response.status_code = 401
        mock_response.text = "Unauthorized"
        mock_response.raise_for_status.side_effect = requests.exceptions.HTTPError("401 Unauthorized")

        with patch('requests.post', return_value=mock_response):
            result = llm_client.chat(user_message)

            # åº”è¯¥è¿”å›é”™è¯¯æç¤ºæ¶ˆæ¯
            assert "ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜" in result or "æ— æ³•å›ç­”" in result

    @pytest.mark.chat
    def test_chat_api_error_5xx(self, llm_client):
        """æµ‹è¯•API 5xxé”™è¯¯"""
        user_message = "æµ‹è¯•æ¶ˆæ¯"

        mock_response = Mock()
        mock_response.status_code = 500
        mock_response.text = "Internal Server Error"
        mock_response.raise_for_status.side_effect = requests.exceptions.HTTPError("500 Internal Server Error")

        with patch('requests.post', return_value=mock_response):
            result = llm_client.chat(user_message)

            # åº”è¯¥è¿”å›é”™è¯¯æç¤ºæ¶ˆæ¯
            assert "ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜" in result or "æ— æ³•å›ç­”" in result

    @pytest.mark.chat
    def test_chat_timeout_error(self, llm_client):
        """æµ‹è¯•è¶…æ—¶é”™è¯¯"""
        user_message = "æµ‹è¯•æ¶ˆæ¯"

        with patch('requests.post', side_effect=requests.exceptions.Timeout("Request timeout")):
            result = llm_client.chat(user_message)

            assert "ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜" in result or "ç¨åå†è¯•" in result

    @pytest.mark.chat
    def test_chat_connection_error(self, llm_client):
        """æµ‹è¯•è¿æ¥é”™è¯¯"""
        user_message = "æµ‹è¯•æ¶ˆæ¯"

        with patch('requests.post', side_effect=requests.exceptions.ConnectionError("Connection failed")):
            result = llm_client.chat(user_message)

            assert "ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜" in result or "ç¨åå†è¯•" in result

    @pytest.mark.chat
    def test_chat_invalid_json_response(self, llm_client):
        """æµ‹è¯•æ— æ•ˆJSONå“åº”"""
        user_message = "æµ‹è¯•æ¶ˆæ¯"

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.side_effect = json.JSONDecodeError("Invalid JSON", "", 0)

        with patch('requests.post', return_value=mock_response):
            result = llm_client.chat(user_message)

            assert "å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯" in result or "ç¨åå†è¯•" in result

    @pytest.mark.chat
    def test_chat_empty_choices_response(self, llm_client):
        """æµ‹è¯•ç©ºchoiceså“åº”"""
        user_message = "æµ‹è¯•æ¶ˆæ¯"

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'choices': []}

        with patch('requests.post', return_value=mock_response):
            result = llm_client.chat(user_message)

            assert "æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜" in result or "ç¨åå†è¯•" in result

    @pytest.mark.chat
    def test_chat_malformed_response(self, llm_client):
        """æµ‹è¯•æ ¼å¼é”™è¯¯çš„å“åº”"""
        user_message = "æµ‹è¯•æ¶ˆæ¯"

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'error': 'Invalid request'}

        with patch('requests.post', return_value=mock_response):
            result = llm_client.chat(user_message)

            assert "æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜" in result or "ç¨åå†è¯•" in result

    @pytest.mark.chat
    def test_chat_retry_mechanism(self, llm_client):
        """æµ‹è¯•é‡è¯•æœºåˆ¶"""
        user_message = "æµ‹è¯•é‡è¯•"

        # æ¨¡æ‹Ÿç¬¬ä¸€æ¬¡å¤±è´¥ï¼Œç¬¬äºŒæ¬¡æˆåŠŸ
        responses = [
            Mock(side_effect=requests.exceptions.ConnectionError("Connection failed")),
            Mock(status_code=200, json=lambda: {
                'choices': [{'message': {'content': 'é‡è¯•æˆåŠŸçš„å›å¤'}}]
            })
        ]

        with patch('requests.post', side_effect=responses):
            result = llm_client.chat(user_message)

            # å¦‚æœå®ç°äº†é‡è¯•æœºåˆ¶ï¼Œåº”è¯¥è¿”å›æˆåŠŸçš„å›å¤
            # å¦‚æœæ²¡æœ‰å®ç°ï¼Œä¼šè¿”å›é”™è¯¯æ¶ˆæ¯
            assert "é‡è¯•æˆåŠŸçš„å›å¤" in result or "ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜" in result

    @pytest.mark.chat
    def test_chat_max_retries_exceeded(self, llm_client):
        """æµ‹è¯•è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°"""
        user_message = "æµ‹è¯•æœ€å¤§é‡è¯•"

        # æ¨¡æ‹Ÿæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        with patch('requests.post', side_effect=requests.exceptions.ConnectionError("Connection failed")):
            result = llm_client.chat(user_message)

            assert "ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜" in result or "ç¨åå†è¯•" in result

    @pytest.mark.chat
    def test_chat_long_conversation_history(self, llm_client):
        """æµ‹è¯•é•¿å¯¹è¯å†å²å¤„ç†"""
        user_message = "å½“å‰é—®é¢˜"

        # åˆ›å»ºå¾ˆé•¿çš„å¯¹è¯å†å²
        long_history = []
        for i in range(20):
            long_history.extend([
                {'role': 'user', 'content': f'ç”¨æˆ·æ¶ˆæ¯{i}'},
                {'role': 'assistant', 'content': f'AIå›å¤{i}'}
            ])

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'choices': [{'message': {'content': 'å¤„ç†é•¿å†å²çš„å›å¤'}}]
        }

        with patch('requests.post', return_value=mock_response) as mock_post:
            result = llm_client.chat(user_message, "", long_history)

            # éªŒè¯å†å²è¢«æˆªæ–­ï¼ˆé€šå¸¸ä¿ç•™æœ€è¿‘å‡ è½®å¯¹è¯ï¼‰
            request_data = mock_post.call_args[1]['json']
            messages = request_data['messages']

            # æ¶ˆæ¯æ•°é‡åº”è¯¥è¢«é™åˆ¶ï¼ˆå…·ä½“æ•°é‡å–å†³äºå®ç°ï¼‰
            assert len(messages) <= 15  # å‡è®¾æœ€å¤šä¿ç•™6è½®å¯¹è¯ + system + å½“å‰ç”¨æˆ·æ¶ˆæ¯

    @pytest.mark.chat
    def test_chat_empty_user_message(self, llm_client):
        """æµ‹è¯•ç©ºç”¨æˆ·æ¶ˆæ¯"""
        user_message = ""

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'choices': [{'message': {'content': 'è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ'}}]
        }

        with patch('requests.post', return_value=mock_response):
            result = llm_client.chat(user_message)

            # åº”è¯¥èƒ½æ­£å¸¸å¤„ç†ç©ºæ¶ˆæ¯
            assert len(result) > 0

    @pytest.mark.chat
    def test_chat_very_long_message(self, llm_client):
        """æµ‹è¯•è¶…é•¿æ¶ˆæ¯å¤„ç†"""
        # åˆ›å»ºä¸€ä¸ªå¾ˆé•¿çš„æ¶ˆæ¯
        user_message = "æµ‹è¯•æ¶ˆæ¯ " * 1000  # å¾ˆé•¿çš„æ¶ˆæ¯

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'choices': [{'message': {'content': 'å¤„ç†é•¿æ¶ˆæ¯çš„å›å¤'}}]
        }

        with patch('requests.post', return_value=mock_response) as mock_post:
            result = llm_client.chat(user_message)

            assert result == 'å¤„ç†é•¿æ¶ˆæ¯çš„å›å¤'

            # éªŒè¯æ¶ˆæ¯è¢«æ­£ç¡®å‘é€
            request_data = mock_post.call_args[1]['json']
            assert 'messages' in request_data

    @pytest.mark.chat
    def test_chat_special_characters(self, llm_client):
        """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å¤„ç†"""
        user_message = "æµ‹è¯•ç‰¹æ®Šå­—ç¬¦ï¼šğŸğŸŒğŸ¥• emoji å’Œ ä¸­æ–‡å­—ç¬¦"

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'choices': [{'message': {'content': 'å¯ä»¥å¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼šğŸğŸŒğŸ¥•'}}]
        }

        with patch('requests.post', return_value=mock_response):
            result = llm_client.chat(user_message)

            assert 'ğŸğŸŒğŸ¥•' in result

    @pytest.mark.chat
    def test_chat_response_content_stripping(self, llm_client):
        """æµ‹è¯•å“åº”å†…å®¹å»é™¤ç©ºç™½å­—ç¬¦"""
        user_message = "æµ‹è¯•æ¶ˆæ¯"

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'choices': [{'message': {'content': '  \n\t  å›å¤å†…å®¹  \n\t  '}}]
        }

        with patch('requests.post', return_value=mock_response):
            result = llm_client.chat(user_message)

            # éªŒè¯å“åº”å†…å®¹è¢«æ­£ç¡®å»é™¤ç©ºç™½å­—ç¬¦
            assert result == 'å›å¤å†…å®¹'

    @pytest.mark.chat
    def test_chat_unicode_handling(self, llm_client):
        """æµ‹è¯•Unicodeå­—ç¬¦å¤„ç†"""
        user_message = "æµ‹è¯•Unicode: cafÃ© naÃ¯ve rÃ©sumÃ©"

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'choices': [{'message': {'content': 'Unicodeå¤„ç†æ­£å¸¸: cafÃ© naÃ¯ve rÃ©sumÃ©'}}]
        }

        with patch('requests.post', return_value=mock_response):
            result = llm_client.chat(user_message)

            assert 'cafÃ© naÃ¯ve rÃ©sumÃ©' in result


class TestLLMClientEdgeCases:
    """æµ‹è¯•LLMå®¢æˆ·ç«¯è¾¹ç•Œæƒ…å†µ"""

    @pytest.fixture
    def llm_client_minimal(self):
        """åˆ›å»ºæœ€å°é…ç½®çš„LLMå®¢æˆ·ç«¯"""
        with patch.dict('os.environ', {
            'LLM_API_KEY': 'test_key',
            'LLM_API_URL': 'https://minimal.api.com',
            'LLM_MODEL': 'minimal-model'
        }):
            with patch('builtins.print'):
                return LLMClient()

    @pytest.mark.chat
    def test_client_with_minimal_config(self, llm_client_minimal):
        """æµ‹è¯•æœ€å°é…ç½®çš„å®¢æˆ·ç«¯"""
        assert llm_client_minimal.api_key == "test_key"
        assert llm_client_minimal.api_url == "https://minimal.api.com"
        assert llm_client_minimal.model == "minimal-model"

    @pytest.mark.chat
    def test_multiple_concurrent_requests(self, llm_client):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†"""
        import threading
        import time

        results = []

        def make_request(message):
            mock_response = Mock()
            mock_response.status_code = 200
            mock_response.json.return_value = {
                'choices': [{'message': {'content': f'å›å¤: {message}'}}]
            }

            with patch('requests.post', return_value=mock_response):
                result = llm_client.chat(message)
                results.append(result)

        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹åŒæ—¶å‘é€è¯·æ±‚
        threads = []
        for i in range(3):
            thread = threading.Thread(target=make_request, args=[f"æ¶ˆæ¯{i}"])
            threads.append(thread)
            thread.start()

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()

        # éªŒè¯æ‰€æœ‰è¯·æ±‚éƒ½å¾—åˆ°äº†å“åº”
        assert len(results) == 3
        for i, result in enumerate(results):
            assert f"æ¶ˆæ¯{i}" in result or "å›å¤:" in result

    @pytest.mark.chat
    def test_system_prompt_customization(self, llm_client):
        """æµ‹è¯•ç³»ç»Ÿæç¤ºè¯è‡ªå®šä¹‰"""
        original_prompt = llm_client.system_prompt

        # ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯
        custom_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ°´æœé”€å”®é¡¾é—®"
        llm_client.system_prompt = custom_prompt

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'choices': [{'message': {'content': 'æˆ‘æ˜¯æ°´æœé”€å”®é¡¾é—®'}}]
        }

        with patch('requests.post', return_value=mock_response) as mock_post:
            llm_client.chat("ä½ å¥½")

            # éªŒè¯è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯è¢«ä½¿ç”¨
            request_data = mock_post.call_args[1]['json']
            messages = request_data['messages']

            system_message = next((msg for msg in messages if msg['role'] == 'system'), None)
            assert system_message is not None
            assert custom_prompt in system_message['content']

        # æ¢å¤åŸå§‹æç¤ºè¯
        llm_client.system_prompt = original_prompt